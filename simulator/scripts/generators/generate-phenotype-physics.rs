// Code generator: Generate phenotype.rs and dynamics.rs from JSON IR

use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};

use serde::Deserialize;

#[derive(Deserialize, Debug)]
struct Constants {
    n_agents: usize,
    gene_len: usize,
    hidden_len: usize,
}

#[derive(Deserialize, Debug)]
struct ConfigIR {
    state_vars: Vec<String>,
    constants: Option<Constants>,
    groups: HashMap<String, GroupConfig>,
    #[serde(default)]
    boundary_conditions: Vec<BoundaryCondition>,
    #[serde(default)]
    initialization: Option<InitializationIR>,
    operations: Vec<Operation>,
}

#[derive(Deserialize, Debug)]
struct BoundaryCondition {
    target_state: String,
    kind: String,
    range: (f64, f64),
}

#[derive(Deserialize, Debug)]
struct InitializationIR {
    state: HashMap<String, Distribution>,
    genes: Distribution,
}

#[derive(Deserialize, Debug)]
#[serde(tag = "kind")]
enum Distribution {
    #[serde(rename = "const")]
    Const { value: f64 },
    #[serde(rename = "uniform")]
    Uniform { low: f64, high: f64 },
    #[serde(rename = "normal")]
    Normal { mean: f64, std: f64 },
    // Legacy sugar (kept for backward compatibility with older IR files).
    #[serde(rename = "zeros")]
    Zeros,
    // Legacy sugar (kept for backward compatibility with older IR files).
    #[serde(rename = "ones")]
    Ones,
}

#[derive(Deserialize, Debug)]
struct GroupConfig {
    activation: String,
    params: Vec<String>,
}

fn ordered_group_names(ir: &ConfigIR) -> Vec<String> {
    let mut names: Vec<String> = Vec::new();
    for preferred in ["physics", "attributes"] {
        if ir.groups.contains_key(preferred) {
            names.push(preferred.to_string());
        }
    }
    let mut rest: Vec<String> = ir
        .groups
        .keys()
        .filter(|k| !names.iter().any(|n| n == *k))
        .cloned()
        .collect();
    rest.sort();
    names.extend(rest);
    names
}

#[derive(Deserialize, Debug)]
struct Operation {
    target: String,
    op: String,
    #[serde(default)]
    args: Vec<String>,
    #[serde(default)]
    value: Option<f64>,
    #[serde(default)]
    dim: Option<i64>,
    #[serde(default)]
    keepdim: Option<bool>,
    #[serde(default)]
    dim0: Option<i64>,
    #[serde(default)]
    dim1: Option<i64>,
}

fn main() {
    let manifest_dir = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
    let repo_root = manifest_dir
        .join("..")
        .join("..")
        .join("..");

    let json_path = repo_root.join("domain-model/_gen/dynamics_ir.json");

    if !json_path.exists() {
        eprintln!("⚠️  dynamics_ir.json not found. Run 'npm run build' in domain-model/ first.");
        eprintln!("   Skipping code generation.");
        return;
    }

    let json_str = fs::read_to_string(&json_path).expect("Failed to read dynamics_ir.json");
    let ir: ConfigIR = serde_json::from_str(&json_str).expect("Invalid JSON format");

    let out_dir = repo_root.join("simulator/src/_gen");

    generate_phenotype(&ir, &out_dir);
    generate_dynamics(&ir, &out_dir);

    println!("✅ Generated Rust code in src/_gen/");
}

fn generate_phenotype(ir: &ConfigIR, out_dir: &Path) {
    let mut code = String::new();
    let group_names = ordered_group_names(ir);

    code.push_str("// AUTO-GENERATED by generate-phenotype-physics.rs - DO NOT EDIT\n\n");

    // Output struct
    code.push_str("#[allow(dead_code)]\n");
    code.push_str("pub struct PhenotypeOutput {\n");
    for name in &group_names {
        code.push_str(&format!("    pub {}: candle_core::Tensor,\n", name));
    }
    code.push_str("}\n\n");

    // Engine struct
    code.push_str("#[allow(dead_code)]\n");
    code.push_str("pub struct PhenotypeEngine {\n");
    code.push_str("    base_net: candle_nn::Sequential,\n");
    for name in &group_names {
        code.push_str(&format!("    head_{}: candle_nn::Linear,\n", name));
    }
    code.push_str("}\n\n");

    // Implementation
    code.push_str("impl PhenotypeEngine {\n");

    // new function
    code.push_str("    #[allow(dead_code)]\n");
    code.push_str(
        "    pub fn new(vs: candle_nn::VarBuilder, input_dim: usize, hidden_dim: usize) -> candle_core::Result<Self> {\n",
    );
    code.push_str("        let base_net = candle_nn::seq()\n");
    code.push_str(
        "            .add(candle_nn::linear(input_dim, hidden_dim, vs.pp(\"base1\"))?)\n",
    );
    code.push_str("            .add(candle_nn::Activation::Relu);\n\n");

    for name in &group_names {
        let data = ir.groups.get(name).expect("group missing");
        let size = data.params.len();
        code.push_str(&format!(
            "        let head_{} = candle_nn::linear(hidden_dim, {}, vs.pp(\"head_{}\"))?;\n",
            name, size, name
        ));
    }

    code.push_str("\n        Ok(Self {\n");
    code.push_str("            base_net,\n");
    for name in &group_names {
        code.push_str(&format!("            head_{},\n", name));
    }
    code.push_str("        })\n");
    code.push_str("    }\n\n");

    // forward function
    code.push_str("    #[allow(dead_code)]\n");
    code.push_str("    pub fn forward(&self, genes: &candle_core::Tensor) -> candle_core::Result<PhenotypeOutput> {\n");
    code.push_str("        let latent = candle_nn::Module::forward(&self.base_net, genes)?;\n\n");

    for name in &group_names {
        let data = ir.groups.get(name).expect("group missing");
        code.push_str(&format!(
            "        let raw_{} = candle_nn::Module::forward(&self.head_{}, &latent)?;\n",
            name, name
        ));

        let activation_code = match data.activation.as_str() {
            "softmax" => format!("candle_nn::ops::softmax(&raw_{}, 1)?", name),
            "tanh" => format!("raw_{}.tanh()?", name),
            "sigmoid" => format!("candle_nn::ops::sigmoid(&raw_{})?", name),
            _ => format!("raw_{}", name),
        };

        code.push_str(&format!(
            "        let val_{} = {};\n",
            name, activation_code
        ));
    }

    code.push_str("\n        Ok(PhenotypeOutput {\n");
    for name in &group_names {
        code.push_str(&format!("            {}: val_{},\n", name, name));
    }
    code.push_str("        })\n");
    code.push_str("    }\n");
    code.push_str("}\n");

    // Gene initialization helper.
    code.push_str("\n#[allow(dead_code)]\n");
    code.push_str("pub fn init_genes(\n");
    code.push_str("    n_agents: usize,\n");
    code.push_str("    gene_len: usize,\n");
    code.push_str("    device: &candle_core::Device,\n");
    code.push_str(") -> candle_core::Result<candle_core::Tensor> {\n");

    let genes_dist = ir.initialization.as_ref().map(|i| &i.genes);

    match genes_dist {
        None => {
            code.push_str(
                "    candle_core::Tensor::randn(0.0f32, 1.0f32, (n_agents, gene_len), device)\n",
            );
        }
        Some(genes_dist) => match genes_dist {
        Distribution::Const { value } => {
            code.push_str(&format!(
                "    let t = candle_core::Tensor::new(&[{}f32], device)?;\n",
                *value as f32
            ));
            code.push_str("    t.broadcast_as((n_agents, gene_len))\n");
        }
        Distribution::Uniform { low, high } => {
            code.push_str(&format!(
                "    candle_core::Tensor::rand({}f32, {}f32, (n_agents, gene_len), device)\n",
                *low as f32, *high as f32
            ));
        }
        Distribution::Normal { mean, std } => {
            code.push_str(&format!(
                "    candle_core::Tensor::randn({}f32, {}f32, (n_agents, gene_len), device)\n",
                *mean as f32, *std as f32
            ));
        }
        Distribution::Zeros => {
            code.push_str("    candle_core::Tensor::zeros((n_agents, gene_len), candle_core::DType::F32, device)\n");
        }
        Distribution::Ones => {
            code.push_str("    candle_core::Tensor::ones((n_agents, gene_len), candle_core::DType::F32, device)\n");
        }
        },
    }

    code.push_str("}\n");

    fs::write(out_dir.join("phenotype.rs"), code).expect("Failed to write phenotype.rs");
}

fn generate_dynamics(ir: &ConfigIR, out_dir: &Path) {
    let mut code = String::new();
    let group_names = ordered_group_names(ir);

    code.push_str("// AUTO-GENERATED by generate-phenotype-physics.rs - DO NOT EDIT\n\n");

    if let Some(constants) = &ir.constants {
        code.push_str(&format!("pub const N_AGENTS: usize = {};\n", constants.n_agents));
        code.push_str(&format!("pub const GENE_LEN: usize = {};\n", constants.gene_len));
        code.push_str(&format!("pub const HIDDEN_LEN: usize = {};\n", constants.hidden_len));
        code.push_str("\n");
    }

    // Export state metadata for the simulator.
    code.push_str(&format!("pub const STATE_DIMS: usize = {};\n", ir.state_vars.len()));
    code.push_str(&format!("pub const STATE_VARS: [&str; {}] = [\n", ir.state_vars.len()));
    for name in &ir.state_vars {
        code.push_str(&format!("    \"{}\",\n", name));
    }
    code.push_str("];\n\n");

    // State initialization helper.
    code.push_str("#[allow(dead_code)]\n");
    code.push_str("pub fn init_state(\n");
    code.push_str("    n_agents: usize,\n");
    code.push_str("    device: &candle_core::Device,\n");
    code.push_str(") -> candle_core::Result<candle_core::Tensor> {\n");

    if let Some(init) = ir.initialization.as_ref() {
        for name in &ir.state_vars {
            let dist = init
                .state
                .get(name)
                .unwrap_or_else(|| panic!("initialization.state missing entry for {}", name));

            let var = format!("init_{}", name);
            match dist {
                Distribution::Const { value } => {
                    code.push_str(&format!(
                        "    let {} = candle_core::Tensor::new(&[{}f32], device)?.broadcast_as((n_agents, 1))?;\n",
                        var,
                        *value as f32
                    ));
                }
                Distribution::Uniform { low, high } => {
                    code.push_str(&format!(
                        "    let {} = candle_core::Tensor::rand({}f32, {}f32, (n_agents, 1), device)?;\n",
                        var,
                        *low as f32,
                        *high as f32
                    ));
                }
                Distribution::Normal { mean, std } => {
                    code.push_str(&format!(
                        "    let {} = candle_core::Tensor::randn({}f32, {}f32, (n_agents, 1), device)?;\n",
                        var,
                        *mean as f32,
                        *std as f32
                    ));
                }
                Distribution::Zeros => {
                    code.push_str(&format!(
                        "    let {} = candle_core::Tensor::zeros((n_agents, 1), candle_core::DType::F32, device)?;\n",
                        var
                    ));
                }
                Distribution::Ones => {
                    code.push_str(&format!(
                        "    let {} = candle_core::Tensor::ones((n_agents, 1), candle_core::DType::F32, device)?;\n",
                        var
                    ));
                }
            }
        }

        code.push_str("\n    candle_core::Tensor::cat(&[\n");
        for name in &ir.state_vars {
            code.push_str(&format!("        &init_{},\n", name));
        }
        code.push_str("    ], 1)\n");
    } else {
        // Fallback for older IR without initialization.
        code.push_str("    // Fallback defaults (domain-model initialization not provided)\n");
        for name in &ir.state_vars {
            let var = format!("init_{}", name);
            if name == "size" {
                code.push_str(&format!(
                    "    let {} = candle_core::Tensor::ones((n_agents, 1), candle_core::DType::F32, device)?;\n",
                    var
                ));
            } else if name.starts_with("pos_") {
                code.push_str(&format!(
                    "    let {} = candle_core::Tensor::rand(-200.0f32, 200.0f32, (n_agents, 1), device)?;\n",
                    var
                ));
            } else {
                code.push_str(&format!(
                    "    let {} = candle_core::Tensor::zeros((n_agents, 1), candle_core::DType::F32, device)?;\n",
                    var
                ));
            }
        }

        code.push_str("\n    candle_core::Tensor::cat(&[\n");
        for name in &ir.state_vars {
            code.push_str(&format!("        &init_{},\n", name));
        }
        code.push_str("    ], 1)\n");
    }

    code.push_str("}\n\n");

    // Function signature
    code.push_str("#[allow(dead_code)]\n");
    code.push_str("pub fn update_dynamics(\n");
    code.push_str("    state: &candle_core::Tensor,\n");
    for name in &group_names {
        code.push_str(&format!("    p_{}: &candle_core::Tensor,\n", name));
    }
    code.push_str(") -> candle_core::Result<candle_core::Tensor> {\n");
    // Decompose state variables
    code.push_str("    // State variable decomposition\n");
    for (i, name) in ir.state_vars.iter().enumerate() {
        code.push_str(&format!(
            "    let s_{} = state.narrow(1, {}, 1)?;\n",
            name, i
        ));
    }
    code.push('\n');

    // Note: population-mixing effects should be expressed as tensor operations in the IR.

    // Decompose parameters
    code.push_str("    // Parameter decomposition\n");
    for g_name in &group_names {
        let g_data = ir.groups.get(g_name).expect("group missing");
        for (i, p_name) in g_data.params.iter().enumerate() {
            code.push_str(&format!(
                "    let p_{} = p_{}.narrow(1, {}, 1)?;\n",
                p_name, g_name, i
            ));
        }
    }
    code.push('\n');

    // Operations
    code.push_str("    // Internal dynamics operations\n");
    for op in &ir.operations {
        let expr = match op.op.as_str() {
            "const" => {
                if let Some(val) = op.value {
                    format!("candle_core::Tensor::new(&[{}f32], state.device())?", val)
                } else {
                    "candle_core::Tensor::new(&[0f32], state.device())?".to_string()
                }
            }
            "ref_param" => {
                // Already decomposed above
                continue;
            }
            "add" if op.args.len() == 2 => {
                format!("{}.broadcast_add(&{})?", op.args[0], op.args[1])
            }
            "sub" if op.args.len() == 2 => {
                format!("{}.broadcast_sub(&{})?", op.args[0], op.args[1])
            }
            "mul" if op.args.len() == 2 => {
                format!("{}.broadcast_mul(&{})?", op.args[0], op.args[1])
            }
            "div" if op.args.len() == 2 => {
                format!("{}.broadcast_div(&{})?", op.args[0], op.args[1])
            }
            "sqrt" if op.args.len() == 1 => {
                format!("{}.sqrt()?", op.args[0])
            }
            "transpose" if op.args.len() == 1 => {
                let d0 = op.dim0.unwrap_or(0);
                let d1 = op.dim1.unwrap_or(1);
                format!("{}.transpose({}, {})?", op.args[0], d0, d1)
            }
            "sum" if op.args.len() == 1 => {
                let dim = op.dim.unwrap_or(0);
                let keepdim = op.keepdim.unwrap_or(true);
                if keepdim {
                    format!("{}.sum_keepdim({})?", op.args[0], dim)
                } else {
                    format!("{}.sum({})?", op.args[0], dim)
                }
            }
            "relu" if op.args.len() == 1 => {
                format!("{}.relu()?", op.args[0])
            }
            "neg" if op.args.len() == 1 => {
                format!("{}.neg()?", op.args[0])
            }
            "add" if op.args.len() == 1 => {
                // Assignment operation (final state update)
                op.args[0].to_string()
            }
            _ => {
                eprintln!("⚠️  Unknown operation: {:?}", op);
                "candle_core::Tensor::new(&[0f32], state.device())?".to_string()
            }
        };

        code.push_str(&format!("    let {} = {};\n", op.target, expr));
    }

    // Boundary conditions (applied after dynamics operations, before returning state)
    if !ir.boundary_conditions.is_empty() {
        code.push_str("\n    // Boundary conditions\n");
        code.push_str("    let n_agents = state.dims()[0];\n");
        for bc in &ir.boundary_conditions {
            if bc.kind != "torus" {
                continue;
            }
            let (min, max) = bc.range;
            let width = max - min;
            code.push_str(&format!(
                "    // torus wrap: {} in [{:.6},{:.6}]\n",
                bc.target_state, min, max
            ));
            code.push_str(&format!(
                "    let mut _bc_col = {}.to_vec2::<f32>()?;\n",
                bc.target_state
            ));
            code.push_str(
                "    let mut _bc_flat: Vec<f32> = _bc_col.into_iter().map(|r| r[0]).collect();\n",
            );
            code.push_str(&format!(
                "    for v in _bc_flat.iter_mut() {{ *v = (*v - ({:.6}f32)).rem_euclid({:.6}f32) + ({:.6}f32); }}\n",
                min, width, min
            ));
            code.push_str(&format!(
                "    let {} = candle_core::Tensor::from_vec(_bc_flat, (n_agents, 1), state.device())?;\n",
                bc.target_state
            ));
        }
    }

    code.push_str("\n    // Concatenate updated state\n");
    code.push_str("    candle_core::Tensor::cat(&[\n");
    for name in &ir.state_vars {
        code.push_str(&format!("        &{},\n", name));
    }
    code.push_str("    ], 1)\n");
    code.push_str("}\n");

    // Primary output
    fs::write(out_dir.join("dynamics.rs"), &code).expect("Failed to write dynamics.rs");

    // Temporary compatibility shim: physics.rs re-exports dynamics.
    let mut shim = String::new();
    shim.push_str("// AUTO-GENERATED compatibility shim - DO NOT EDIT\n\n");
    shim.push_str("include!(\"dynamics.rs\");\n");
    shim.push_str("\n#[allow(dead_code)]\n");
    shim.push_str("pub fn update_physics(\n");
    shim.push_str("    state: &candle_core::Tensor,\n");
    for name in &group_names {
        shim.push_str(&format!("    p_{}: &candle_core::Tensor,\n", name));
    }
    shim.push_str(") -> candle_core::Result<candle_core::Tensor> {\n");
    shim.push_str("    update_dynamics(state");
    for name in &group_names {
        shim.push_str(&format!(", p_{}", name));
    }
    shim.push_str(")\n}\n");
    fs::write(out_dir.join("physics.rs"), shim).expect("Failed to write physics.rs");
}
